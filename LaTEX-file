\documentclass[bachelor, och, coursework, times]{SCWorks}
% параметр - тип обучения - одно из значений:
%    spec     - специальность
%    bachelor - бакалавриат (по умолчанию)
%    master   - магистратура
% параметр - форма обучения - одно из значений:
%    och   - очное (по умолчанию)
%    zaoch - заочное
% параметр - тип работы - одно из значений:
%    referat    - реферат
%    coursework - курсовая работа (по умолчанию)
%    diploma    - дипломная работа
%    pract      - отчет по практике
%    pract      - отчет о научно-исследовательской работе
%    autoref    - автореферат выпускной работы
%    assignment - задание на выпускную квалификационную работу
%    review     - отзыв руководителя
%    critique   - рецензия на выпускную работу
% параметр - включение шрифта
%    times    - включение шрифта Times New Roman (если установлен)
%               по умолчанию выключен
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage{graphicx}
\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{array}
\usepackage[english,russian]{babel}
\usepackage[colorlinks=true]{hyperref}

\newcommand{\eqdef}{\stackrel {\rm def}{=}}

\newtheorem{lem}{Лемма}

\begin{document}

% Кафедра (в родительном падеже)
\chair{математической кибернетики и компьютерных наук}

% Тема работы
\title{Реализация формальных грамматик на языке С}

% Курс
\course{2}

% Группа
\group{251}

% Факультет (в родительном падеже) (по умолчанию "факультета КНиИТ")
%\department{факультета КНиИТ}

% Специальность/направление код - наименование
%\napravlenie{02.03.02 "--- Фундаментальная информатика и информационные технологии}
%\napravlenie{02.03.01 "--- Математическое обеспечение и администрирование информационных систем}
%\napravlenie{09.03.01 "--- Информатика и вычислительная техника}
\napravlenie{09.03.04 "--- Программная инженерия}
%\napravlenie{10.05.01 "--- Компьютерная безопасность}

% Для студентки. Для работы студента следующая команда не нужна.
%\studenttitle{Студентки}

% Фамилия, имя, отчество в родительном падеже
\author{Волкова Даниила Андеевича}

% Заведующий кафедрой
\chtitle{к.\,ф.-м.\,н.} % степень, звание
\chname{С.\,В.\,Миронов}

%Научный руководитель (для реферата преподаватель проверяющий работу)
\satitle{доцент, к.\,ф.-м.\,н.} %должность, степень, звание
\saname{Г.\,Г.\,Наркайтис}

% Руководитель практики от организации (только для практики,
% для остальных типов работ не используется)
\patitle{к.\,ф.-м.\,н., доцент}
\paname{Д.\,Ю.\,Петров}

% Семестр (только для практики, для остальных
% типов работ не используется)
\term{2}

% Наименование практики (только для практики, для остальных
% типов работ не используется)
\practtype{учебная}

% Продолжительность практики (количество недель) (только для практики,
% для остальных типов работ не используется)
\duration{2}

% Даты начала и окончания практики (только для практики, для остальных
% типов работ не используется)
\practStart{01.07.2016}
\practFinish{14.07.2016}

% Год выполнения отчета
\date{2016}

\maketitle

% Включение нумерации рисунков, формул и таблиц по разделам
% (по умолчанию - нумерация сквозная)
% (допускается оба вида нумерации)
%\secNumbering

\tableofcontents

% Раздел "Обозначения и сокращения". Может отсутствовать в работе
%\abbreviations
%\begin{description}
%    \item $|A|$  "--- количество элементов в конечном множестве $A$;
%    \item $\det B$  "--- определитель матрицы $B$;
%    \item ИНС "--- Искусственная нейронная сеть;
%    \item FANN "--- Feedforward Artifitial Neural Network
%\end{description}

% Раздел "Определения". Может отсутствовать в работе
%\definitions

% Раздел "Определения, обозначения и сокращения". Может отсутствовать в работе.
% Если присутствует, то заменяет собой разделы "Обозначения и сокращения" и "Определения"
%\defabbr

% Раздел "Введение"
\intro
Лексический и синтаксический анализ --- широко распространенный инструмент в современных информационных технологиях. Он применяется во всех без исключения компиляторах, переводчиках и системах проверки правописания, которые используются повсеместно в браузерах и текстовых редакторах.

В последнее время большое значение приобрела задача построения синтаксических анализаторов для, так называемых, контекстно-свободных открытых языков, то есть языков, задаваемых контекстно-свободной грамматикой, которая может быть расширена.

Целью настоящей работы является создание калькулятора с использованием лексического и синтаксического анализаторов flex и bison. Результатом должна быть программа, получающая строку в виде математического выражения и выдающая его результат.

\section{Структура формальных грамматик}
\subsection{Лексический анализатор}

Лексический анализ  --- это процесс разбиения входных данных на последовательности символов, которые именуются "токенами". Группа символов, распознанная как токен, называется лексемой. Каждый токен однозначно характеризует лексему. А лексема, в свою очередь, однозначно определяет некоторую конструкцию языка. При лексическом анализе распознаются и выделяются лексемы из входной последовательности.

Лексический анализ проводится на основе заданного алфавита или набора языков, и грамматика языка задает список лексем, которые допустимо встретить во входных данных.
Традиционно принято организовывать входную последовательность как поток. При таком подходе процесс сам управляет выборкой символов из входного потока.

Распознавание лексем осуществляется путем их классификации согласно грамматике языка. 
И если очередная последовательность символов не соответствует ни одному типу допустимых лексем, то она считается специальным токеном-ошибкой.

Лексический анализатор --- это программа, которая осуществляет лексический анализ.
То, как будет представлен результат работы лексического анализатора в основном зависит от версии компилятора, но в общем виде его можно представить как таблицу лексем, где для каждой лексемы хранится необходимая служебная информация.

Обычно лексический анализатор работает в 2 этапа: сканирование и оценка.

На первом этапе формируется конечный автомат, характеризуемый регулярными выражениями, то есть собирается информация о том, какие токены допустимы в данном примере. Например, токен "вещественное число" может представляться в виде двух последовательностей цифр, разделенных точкой.

На втором этапе осуществляется разбор входной последовательности, происходит процесс распознавания токенов. Поочередно просматриваются элементы последовательности, пока не встретится запрещенный для данного токена символ. В сложных примерах может возникать ситуация, когда правила разбора не позволяют одним проходом однозначно идентифицировать все лексемы, тогда потребуется возврат назад по читаемой последовательности.

Полученные в результате анализа лексемы передаются синтаксическому анализатору.~\cite{FaB}

\begin{figure}  [!ht]
	\centering
	\includegraphics[width=15cm]{bison.png}
\end{figure}

\subsection{Синтаксический анализатор}

Синтаксический анализ --- это сопоставление последовательного набора лексем формального языка с его формальной грамматикой.
В процессе анализа входные данные представляются в виде дерева, так как оно хорошо подходит для дальнейшей обработки. Это может быть дерево составляющих, дерево зависимостей, другие структуры или сочетания нескольких способов представления.

Во время синтаксического анализа производится проверка корректности данных, представленных в виде последовательности токенов и совокупности таблиц, и преобразование программы во внутреннюю форму, удобную для последующей обработки. Обычно применяется совместно с лексическим анализом.

Задачи синтаксического анализа:
\begin{itemize}
\item определить, совпадает ли структура цепочки лексем со структурой, заданной синтаксисом языка;
\item зафиксировать данную структуру.
\end{itemize}

Синтаксический анализатор --- это программа, выполняющая синтаксический анализ.
Формально синтаксический анализатор является вычислимой функцией двух аргументов:
\begin{itemize}
\item Входная строка $w = a_1...a_n$ длины $|w| = n$, где $a_i \in T$, $1 \leqslant i \leqslant n$;
\item KC-грамматика $G = \{N, T, P, S\}$, где $S$ --- стартовый нетерминальный символ грамматики, $P$ --- правила языка, $T$ --- терминалы, $N$ --- нетерминальные символы языка.
\end{itemize}

Функция осуществляет построение и, если входная строка $w$ принадлежит языку $L(G)$, заданному грамматикой $G$, выдает дерево вывода $T_G$, этой строки в грамматике $G$ или $false$ - в противном случае.

На этапе синтаксического анализа устанавливается порядок следования символов в программе и становится ясной общая структура программы. Таким образом, анализатор должен понимать контекст, в котором производятся вычисления и учитывать уже прочитанные символы.

Чтобы построить синтаксический анализатор выражений языка используют несколько различных методов.

Рекурсивный нисходящий синтаксический анализатор представляется в виде рекурсивных функций, вызывающих друг друга, которые обрабатывают выражение. Если работа анализатора происходит в компиляторе, то генерируется объектный код, который соответствует исходному тексту программы.
А в интерпретаторе анализатор вычисляет значение заданного выражения.

Синтаксические анализаторы могут быть построены автоматически из определений языка. Такие анализаторы называются управляемыми таблицей, они создаются генераторами программ. В общем случае такие анализаторы обеспечивают более быструю работу, но процесс их создания достаточно трудоемкий, в частности потребуется форматировать абстрактное синтаксическое дерево.

Этап синтаксического анализа является ключевым, так как он непосредственно взаимодействует с лексической фазой и обеспечивает создание основы для работы компилятора.~\cite{FaB}

\section{Реализация формальных грамматик на языке C}
\subsection{Flex}

Flex --- это инструмент для лексического анализа текста, который генерирует лексические анализаторы. На базе пакетов GNU заменяет UNIX-генератор Lex, при этом имеет аналогичную функциональность и расшифровывается как "Fast LEX".

Flex генерирует программы, распознающие шаблоны в тексте. Он создает программу, которая, используя заданные правила поиска, использует их в шаблонах. Преимущество Flex в простоте задания правил по сравнению с написанием собственных инструментов для поиска по шаблону.

Генератор получает на вход цепочки символов и правила выделения лексем, которые необходимо выполнить в случае успеха распознавания. После выполнения в качестве выходных данных выдает код анализатора в виде функции на языке С.

Полученную функцию часто используют совместно с генераторами синтаксических анализаторов. Они используют для поиска следующей лексемы функцию yylex(), которую сгенерировал Flex. Обычно Flex используют с YACC или GNU bison. 

% %
Flex работает по следующему принципу. Сначала подготавливается спецификация лексического анализатора на языке Lex --- получается файл lex.l. Потом полученный файл компилируется Lex-ом для получения программы на языке С. Результат - lex.yy.c. Эта программа содержит диаграмму переходов в виде таблицы, построенной по регулярным выражениям файла lex.l и программу, использующую эту таблицу для распознавания лексем.

\begin{figure}  [!ht]
	\centering
	\includegraphics[width=15cm]{lex.png}
\end{figure}

Действия с регулярными выражениями представляются в виде фрагментов кода на языке С, которые переносятся в lex.yy.c. Далее полученная программа lex.yy.c компилируется стандартным С компилятором, в результате чего создается программа a.out, которая и является лексическим анализатором, преобразовывающим входную последовательность символов в набор токенов.




Программа Flex содержит 3 раздела, отделяющиеся строкой «\%\%»: \\
Блок объявлений \\
\%\% \\
Блок правил \\
\%\% \\
Блок вспомогательных процедур \\

Раздел объявлений включается в себя именованные константы, объявления переменных, макросов и регулярные определения.

Раздел правил представляется в виде: \\
$s_1$ \{$instruction_1$\} \\
$s_2$ \{$instruction_2$\} \\
$s_3$ \{$instruction_3$\}, \\

где $s_i$ --- регулярное выражение, а $instruction_i$ --- фрагмент кода, который необходимо выполнить лексическому анализатору, если лексема соответствует шаблону $s_i$.

Третий раздел представляет собой различные пользовательские функции, которые могут быть скомпилированы отдельно и загружены совместно с лексическим анализатором.

Лексический анализатор, созданный Flex, работает вместе с синаксическим анализатором в связке. Когда синтаксический анализатор активирует лексический, то последний начинает чтение оставшейся части входной последовательности по одному символу, пока сохраняется соответствие с одним из регулярных выражений $s_i$. Далее выполняется действие $instruction_i$.

Лексический анализатор возвращает синтаксическому анализатору только один параметр --- найденный токен. Для передачи информации об этом токене используется глобальная переменная yylval.~\cite{Rl}

\subsection{Bison}

Bison --- это инструмент для грамматического разбора текста, который генерирует синтаксические анализаторы на основе грамматики, описанной в нотации BNF (форма Бэкуса-Наура) или контекстно-свободной грамматики.

GNU Bison может использоваться для преобразования входной последовательности токенов в структурированный формат для дальнейшей обработки. На выходе выдает программу-парсер на языке С.

Bison работает только с грамматиками класса LALR(1), то есть необходимо, чтобы была возможность разобрать любую последовательность, заглядывая вперед не более, чем на одну лексему.

Чтобы Bison смог разобрать программу на некотором языке, нужно чтобы данный язык был описан контекстно-свободной грамматикой. Таким образом, любая синтаксическая группа должна составляться из составных частей. При этом допустимо рекурсивное определение, однако в таком случае необходимо присутствие хотя бы одного правила, выводящего из рекурсии.

Код анализатора --- это код, определяющий функцию yyparse, которая реализует грамматику. Также для корректной работы необходимы дополнительные функции. Одна из них --- лексический анализатор.

Главная задача Bison --- это объединение лексем в группы в с соответствии с правилами грамматики. Часто Bison используют совместно с генератором лексических анализаторов Flex. И Bison вызывает лексический анализатор, когда ему необходима очередная лексема.

Общая структура программы выглядит так: \\
\%\{ \\
Объявления C \\
\%\} \\
Объявления Bison \\
\%\% \\
Правила грамматики \\
\%\% \\
Дополнительный код на C \\

Раздел Объявления С состоит из определений типов, переменных, функций, которые необходимы для выполнения действий правил грамматики, а также макросов и других директив препроцессора.

Объявления Bison определяют имена нетерминальных и терминальных символов, описывают типы данных семантических значений и задают приоритет операций.

Правила грамматики устанавливают связи между нетерминальными символами, а именно из каких частей они состоят. Должно быть хотя бы одно правило грамматики.

Дополнительный код на С копируется в конец файла анализатора. К примеру, тут может находиться функция yylex(). Эта секция в отличие от предыдущей может остаться пустой. Тогда допустимо не ставить последние \%\%.

Правила грамматики представляются в следующем виде:

$expr$: \quad $components$ \{$action$\} ; \\

где $expr$ --- это описываемый правилом нетерминальный символ,\\ $components$ --- различные терминальные и нетерминальные символы, объединяемые этим правилом, $action$ --- действие, которое необходимо выполнить в случае соответствия текущего набора типов лексем данной грамматике.

Действие выглядит в виде кода на С, который должен выполняться, если правилу соответствует данных текст. Обычно действие вычисляет семантическое значение группы, исходя из семантических значений компонент.~\cite{Generator}

\subsection{Makefile}

Проект состоит из нескольких отдельных программ. При внесении правок в исходный код отладке программы приходится перекомпилировать каждый файл и собирать его в единое целое по несколько раз. Чтобы не делать это вручную, можно воспользоваться стандартной утилитой GNU make. Она самостоятельно принимает решение о том, какие файлы нужно перекомпилировать и выполняет необходимые действия.

Для того, чтобы использовать make, нужно создать make-файл, описывающий зависимости между частями проекта и содержащий команды для их обновления. Обычно исполняемый файл зависит от объектных файлов, которые, в свою очередь, зависят от файлов с исходным кодом.

После создания make-файла достаточно просто ввести команду <<make>> и все необходимые файлы будут перекомпилированны. Утилита make на основе данных о последних модификациях частей проекта обновляет устаревшие файлы. Для всех них выполняются указанные в makefile команды.

В общем случае makefile выглядит как набор из правил следующего вида:

$target$: \quad $dependencies$ \\
$ $\quad \quad \quad \quad \quad \quad $command$

Target представляет собой имя файла, которое генерируется в процессе сборки. Dependencies --- файл, используемый для порождения цели. Command --- действие, которое необходимо выполнить, если dependencies устарели.

Правило описывает, каким образом необходимо обновлять файлы или как должно выполняться некоторое действие. Файл должен быть перекомпилирован всякий раз, когда изменилась одна из его зависимостей. При этом все зависимости, которые генерируются автоматически, должный быть обновлены первыми. 

По умолчанию, make начинает работать с первой встреченной целью. Эта цель выбирается целью по умолчанию. Главная цель --- это цель, которую стремится достичь make, как результат своей работы. Другие правила обрабатываются только потому, что их цели являются прямыми или косвенными зависимостями для главной цели.

Makefile может состоять из пяти видов конструкций: явные и неявные правила, директивы, определения переменных и комментарии.

В явное правило перечисляются файлы, от которых зависит цель, и могут быть заданы команды, необходимые для обновления цели.

Неявное правило описывает, как следует обновлять некоторую группу файлов, подходящих под определенный шаблон. Оно определят, как цель зависит от файла с таким же именем и задает команду для создания или обновления цели.

Определение переменной представлено в виде строки, в которой переменной присваивается некоторое текстовое значение. Далее это значение может быть подставлено в нужное место текста.

Директива определяет специальное действие, которое необходимо совершить во время чтения make-файла (например, определение многострочной переменной или подключение другого make-файла).

Символ <<\#>> обозначает комментарий. Весь текст от него и до конца строки будет игнорирован.~\cite{Make}

\section{Пример реализации арифметических операций}
\subsection{Сложение и вычитание}
Сперва реализуем калькулятор, который будет поддерживать только сложение и вычитание целых чисел.
Нам понадобится два файла: $calc1.l$ и $calc1.y$. Лексический и синтаксических анализатор соответственно.

Поскольку нам нужно из потока выбирать только целые числа, опишем в $calc1.l$ правило для них (строки 10-13 приложения \ref{pril-2}).
Целое число есть последовательность одной или более цифр от 0 до 9. В Bison передается значение числа и название его токена.

Все, что числом не является, будем считать арифметическим знаком (строки 14-16 приложения \ref{pril-2}). Если же в Bison был отправлен не знак, а недопустимая лексема, то она будет обработана как ошибка.

Полный код программы calc1.l находится в приложении \ref{pril-2}.

$Calc1.y$ будет обрабатывать лексемы, которые выделил Flex, в соответствии с написанной грамматикой (строки 29-36 приложения \ref{pril-3}).

Разбор всех лексем можно представить в форме Бэкуса-Наура: \linebreak
<expr> ::= <expr> + <expr> | <expr> - <expr> | NUMBER,

где NUMBER --- это уже определенный Flex-ом токен, соответствующий целому числу.

Полный код программы $calc1.y$ находится в приложении \ref{pril-3}.

Сборкой анализаторов будет заниматься Makefile.

Полный код программы Makefile находится в приложении \ref{pril-1}.

\subsection{Приоритеты}
Добавим операции умножения и деления. Теперь выражения должны иметь разный приоритет подсчета. Добавим также возможность разбора выражений со скобками.

Лексический анализатор не будет ничем отличаться от старого. Новые операции и скобки будут также учитываться только в Bison.

Полный код программы $calc2.l$ находится в приложении \ref{pril-4}.

В синтаксическом анализаторе дадим операциям <<*>> и <</>> больший приоритет, нежели <<+>> и <<->>. (строка 12 приложения \ref{pril-5})

Также изменим правило разбора выражений (строки 25-51 приложения \ref{pril-5}):

<expr> ::= '(' <expr> ')' | <expr> + <expr> | <expr> - <expr> | <expr> * <expr> | <expr> / <expr> | NUMBER.

В разбор выражения с делением добавим проверку на неравенство нулю делителя (строки 47-50 приложения \ref{pril-5}).

Полный код программы $calc2.y$ находится в приложении \ref{pril-5}.

\subsection{Типизация}
Теперь калькулятор должен поддерживать 3 типа чисел: целые, дробные и комплексные. При этом должно быть реализовано приведение типов.

К примеру, 3 / 2 должно быть равно 1, а 3.0 / 2 должно быть равно 1,5.

Добавим в $calc3.l$ незначительные изменения.

Добавим выбор мнимой единицы из потока для комплексной записи числа (строки 14-18 приложения \ref{pril-6}) и выбор дробного числа из потока (строки 19-23 приложения \ref{pril-6})

Полный код программы calc3.l находится в приложении \ref{pril-6}.

В calc3.y же внести изменений нужно куда больше.

Опишем для токенов новый тип (по умолчанию значение в токенах является целочисленным) в файле $typedef.h$.

Полный код файла $typedef.h$ находится в приложении \ref{pril-8}

Тип $struct\_value$ состоит из двух полей: $type\_value$ - название типа, которое может быть $INTEGER$, $DOUBLE$ или $COMPLEX$, и union, в котором хранится соответствующее типу значение. 

Теперь операнды математических операций будут сравниваться функцией $high\_type$ (строки 8-17 приложения \ref{pril-7}). Операнд с меньшим типом будет приводиться к старшему функцией $cast\_to\_target\_type$ (строки 19-49 приложения \ref{pril-7}). Только после приведения к одинаковым типам операндов выражение будет высчитываться.

Полный код программы $calc3.y$ находится в приложении \ref{pril-7}.

% Раздел "Заключение"
\conclusion
В ходе выполнения курсовой работы были изучены и отработаны навыки по следующим темам:
\begin{itemize}
	\item работа с операционной системой Linux;
	\item написание программ на языке С;
	\item разработка лексического анализатора;
	\item разработка синтаксического анализатора;
	\item работа с утилитой Make;
	\item комплексные числа в языке C;
	\item работа со структурами union и enum языка C;
	\item формальные грамматики;
\end{itemize}


%Библиографический список, составленный вручную, без использования BibTeX
%
%\begin{thebibliography}{99}
%  \bibitem{Ione} Источник 1.
%  \bibitem{Itwo} Источник 2
%\end{thebibliography}

%Библиографический список, составленный с помощью BibTeX
%
\bibliographystyle{gost780uv}
\bibliography{thesis}

% Окончание основного документа и начало приложений
% Каждая последующая секция документа будет являться приложением
\appendix

\section{Листинг программы <<Makefile>>}\label{pril-1}

\begin{Verbatim}[fontsize=\small, numbers=left]
calc: lex.calc.c calc.tab.h calc.tab.c
	$(CC) calc.tab.c lex.calc.c -o calc

lex.calc.c: calc.l
	$(LEX) $^

calc.tab.c: calc.y
	$(YACC) $^

calc.tab.h: calc.y
	$(YACC)  $^
\end{Verbatim}

\section{Листинг программы <<calc1.l>>}\label{pril-2}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include "calc.tab.h"
%}

%option prefix="calc"

%%
" "     ;
[0-9]+    {
              calclval = atoi(calctext);
              return NUMBER;
          }
[^0-9]    {             
             return calctext[0]; 
          }
%%
\end{Verbatim}

\section{Листинг программы <<calc1.y>>}\label{pril-3}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include <string.h>
%}

%file-prefix "calc"
%name-prefix "calc"

%defines

%left '+' '-'

%start main

%token NUMBER

%%   

main:    expr  '\n'
         {
             printf("%d\n", $1);
         }
         ;

expr:    expr '+' expr
         {
             $$ = $1 + $3;
         }
         |
         expr '-' expr
         {
             $$ = $1 - $3;
         }
         |
         NUMBER
         ;       
%%

extern struct calc_buffer_state* calc_scan_string(char* str);
main(int argc, char* argv[])
{
   int buf_size = 2;
   int i;
   for (i = 1; i < argc; i++)
   {
      buf_size += strlen(argv[i]);
   }
   char buf[buf_size];
   char* ptr = buf;
   for (i = 1; i < argc; ++i)
   {
      char* arg;
      for (arg = argv[i]; *arg; )
         *ptr++ = *arg++;
   }
   *ptr++ = '\n';
   *ptr = 0;
   struct calc_buffer_state* buffer = calc_scan_string(buf);
   calcparse();
}

calcerror()
{
   printf("Error\n");
}

calcwrap()
{
   return(1);
}
\end{Verbatim}

\section{Листинг программы <<calc2.l>>}\label{pril-4}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include "calc.tab.h"
%}

%option prefix="calc"

%%
" "     ;
[0-9]+    {
              calclval = atoi(calctext);
              return NUMBER;
          }
[^0-9]    {             
              return calctext[0]; 
          }
%%

\end{Verbatim}

\section{Листинг программы <<calc2.y>>}\label{pril-5}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include <string.h>
%}

%file-prefix "calc"
%name-prefix "calc"

%defines

%left '+' '-'
%left '*' '/'

%start main

%token NUMBER

%%

main:     expr '\n'
         {
             printf("%d\n", $1);
         }
         ;
expr:    '(' expr ')'
         {
             $$ = $2;
         }
         |
         expr '+' expr
         {
             $$ = $1 + $3;
         }
         |
         expr '-' expr
         {
             $$ = $1 - $3;
         }
         |
         expr '*' expr
         {
             $$ = $1 * $3;
         }
         |
         expr '/' expr
         {
             if ($3 == 0)
                calcerror();
             else
                $$ = $1 / $3;
         }
         |
         NUMBER
         ;      
%%

extern struct calc_buffer_state* calc_scan_string(char* str);
main(int argc, char* argv[])
{
   int buf_size = 2;
   int i;
   for (i = 1; i < argc; i++)
   {
      buf_size += strlen(argv[i]);
   }
   char buf[buf_size];
   char* ptr = buf;
   for (i = 1; i < argc; ++i)
   {
      char* arg;
      for (arg = argv[i]; *arg; )
         *ptr++ = *arg++;
   }
   *ptr++ = '\n';
   *ptr = 0;
   struct calc_buffer_state* buffer = calc_scan_string(buf);
   calcparse();
}

calcerror()
{
   printf("Error\n");
}

calcwrap()
{
   return(1);
}
\end{Verbatim}

\section{Листинг программы <<calc3.l>>}\label{pril-6}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <stdio.h>
#include <complex.h>
#include "typedef.h"
#include "calc.tab.h"
%}

%option prefix="calc"

%%

" "               ;

[i]               {
                     calcval.value.type = COMPLEX;
                     calcval.value.cval = I;
                     return NUMBER;
                  }
[0-9]+\.[0-9]+    {
                      calclval.value.type = DOUBLE;
                      calclval.value.dval = atof(calctext);
                      return NUMBER;
                  }
[0-9]+            {
                      calclval.value.type = INTEGER;
                      calclval.value.ival = atoi(calctext);
                      return NUMBER;
                  }
[^0-9]            {             
                      return calctext[0]; 
                  }
%%
\end{Verbatim}

\section{Листинг программы <<calc3.y>>}\label{pril-7}

\begin{Verbatim}[fontsize=\small, numbers=left]
%{
#include <complex.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include "typedef.h"

type_value high_type(type_value t1, type_value t2)
{
  if (t1 == COMPLEX || t2 == COMPLEX)
    return COMPLEX;
  else
    if (t1 == DOUBLE || t2 == DOUBLE)
      return DOUBLE;
    else
      return INTEGER;
}

void cast_to_target_type(type_value target, struct_value *val)
{
  switch(target)
  {
  case COMPLEX:
    switch(val->type)
    {
    case COMPLEX:
      break;
    case DOUBLE:
      val->cval = val->dval;
      break;
    case INTEGER:
      val->cval = val->ival;
      break;
    }
    break;
  case DOUBLE:
    switch(val->type)
    {
    case DOUBLE:
      break;
    case INTEGER:
      val->dval = val->ival;
      break;
    }
    break;
  case INTEGER:
    break;
  }
}
%}

%file-prefix "calc"
%name-prefix "calc"

%defines

%union
{
  struct_value value;
};

%left '+' '-'
%left '*' '/'

%start main

%token <value> NUMBER
%type <value> expr

%%

main: expr '\n'
      {
	switch($1.type)
	{
	case COMPLEX:
	  printf("%f + %fi\n", creal($1.cval), cimag($1.cval));
	  break;
	case DOUBLE:
	  printf("%f\n", $1.dval);
	  break;
	case INTEGER:
	  printf("%d\n", $1.ival);
	  break;
	}
      }
      ;
expr: '(' expr ')'
      {
	switch($2.type)
	{
	case COMPLEX:
	  $$.type = COMPLEX;
	  $$.cval = $2.cval;
	  break;
	case INTEGER:
	  $$.type = INTEGER;
	  $$.ival = $2.ival;
	  break;
	case DOUBLE:
	  $$.type = DOUBLE;
	  $$.dval = $2.dval;
	  break;
	}
      }
      |
      expr '+' expr
      {
	$$.type = high_type($1.type, $3.type);
	cast_to_target_type($$.type, &$1);
	cast_to_target_type($$.type, &$3);
	
	switch($$.type)
	{
	case COMPLEX:
	  $$.cval = $1.cval + $3.cval;
	  break;
	case DOUBLE:
	  $$.dval = $1.dval + $3.dval;
	  break;
	case INTEGER:
	  $$.ival = $1.ival + $3.ival;
	  break;
	}
      }
      |
      expr '-' expr
      {
	$$.type = high_type($1.type, $3.type);
	cast_to_target_type($$.type, &$1);
	cast_to_target_type($$.type, &$3);
	switch($$.type)
	{
	case COMPLEX:
	  $$.cval = $1.cval - $3.cval;
	  break;
	case DOUBLE:
	  $$.dval = $1.dval - $3.dval;
	  break;
	case INTEGER:
	  $$.ival = $1.ival - $3.ival;
	  break;
	}
      }
      |
      expr '*' expr
      {
	$$.type = high_type($1.type, $3.type);
	cast_to_target_type($$.type, &$1);
	cast_to_target_type($$.type, &$3);
	switch($$.type)
	{
	case COMPLEX:
	  $$.cval = $1.cval * $3.cval;
	  break;
	case DOUBLE:
	  $$.dval = $1.dval * $3.dval;
	  break;
	case INTEGER:
	  $$.ival = $1.ival * $3.ival;
	  break;
	}
      }
      |
      expr '/' expr
      {
	$$.type = high_type($1.type, $3.type);
	cast_to_target_type($$.type, &$1);
	cast_to_target_type($$.type, &$3);
	switch($$.type)
	{
	case COMPLEX:
	  if (creal($3.cval) == 0.0 && cimag($1.cval) == 0.0)
	    calcerror();
	  else
	    $$.cval = $1.cval / $3.cval;
	  break;
	case DOUBLE:
	  if ($3.dval == 0.0)
	    calcerror();
	  else
	    $$.dval = $1.dval / $3.dval;
	  break;
	case INTEGER:
	  if ($3.ival == 0)
	    calcerror();
	  else
	    $$.ival = $1.ival / $3.ival;
	  break;
	}
      }
      |
      NUMBER
      {
	switch($1.type)
	{
	case COMPLEX:
	  $$.type = COMPLEX;
	  $$.cval = $1.cval;
	  break;
	case DOUBLE:
	  $$.type = DOUBLE;
	  $$.dval = $1.dval;
	  break;
	case INTEGER:
	  $$.type = INTEGER;
	  $$.ival = $1.ival;
	  break;
	}
      }
      ;
%%

extern struct calc_buffer_state* calc_scan_string(char* str);
main(int argc, char* argv[])
{
  int buf_size = 2;
  int i;
  for (i = 1; i < argc; i++)
  {
    buf_size += strlen(argv[i]);
  }
  char buf[buf_size];
  char* ptr = buf;
  for (i = 1; i < argc; ++i)
  {
    char* arg;
    for (arg = argv[i]; *arg; )
      *ptr++ = *arg++;
  }
  *ptr++ = '\n';
  *ptr = 0;
  struct calc_buffer_state* buffer = calc_scan_string(buf);
  calcparse();
}

calcerror()
{
  printf("Error!\n");
}

calcwrap()
{
  return(1);
}
\end{Verbatim}

\section{Листинг программы <<typedef.h>>}\label{pril-8}

\begin{Verbatim}[fontsize=\small, numbers=left]
typedef enum
{
   INTEGER,
   DOUBLE,
   COMPLEX
} type_value;

typedef struct
{
   type_value type;
   union
   {
      int ival;
      double dval;
      double complex cval;
   };
} struct_value;
\end{Verbatim}

\end{document}
